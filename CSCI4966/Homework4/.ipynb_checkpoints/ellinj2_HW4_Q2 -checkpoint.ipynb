{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WarGZV8EV0JL"
   },
   "source": [
    "### Question 2 CNN for CIFAR10 dataset in PyTorch\n",
    "\n",
    "#### To be run on GPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 (1) Torch imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate size of output of final convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_image_size(layers,size_in,padding=0,kernel=3,stride=2,dilation=1):\n",
    "    \"\"\"layers: the number of maxPool operations\n",
    "       size_in: height or width of image\n",
    "       \"\"\"\n",
    "    for _ in range(layers):\n",
    "        size_in = np.floor(((size_in + 2*padding - dilation*(kernel-1)-1)/stride)+1)\n",
    "        #print(size_in)\n",
    "    return int(size_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 (2) Download and transform Cifar10 data from torchvision\n",
    "\n",
    "* The Cifar10 dataset has 3 color channels\n",
    "* Show the shape of the training data and the type the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-UhN3O81Kww0",
    "outputId": "91eb44f9-64bc-472c-e1bd-c32adee28cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), dtype('uint8'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "transformer_train = torchvision.transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4),\n",
    "  torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "  transforms.ToTensor(),])\n",
    "\n",
    "# Your Code Here\n",
    "train_data = torchvision.datasets.CIFAR10(root=\".\", train=True, transform=transformer_train, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\".\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_data.data.shape, test_data.data.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 (1) Create train and test loaders using mini-batch size of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_lH3-1XLDS1"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 (8) Create CNN Model Class\n",
    "\n",
    "* Create 2 blocks, conv1 and conv2 of convolutional layers using the Sequential class for each block.\n",
    "    - Inside the block should be  a two conv2d classes with 32 output channels, two ReLU and two Batch Normalizations  \n",
    "    \n",
    "* Create two linear layers, linear1 and linear2, linear1 should have an output of 1024 channels  \n",
    "* In the forward function wrap linear1 in a ReLU and add a dropout layer after it  \n",
    "\n",
    "* Hint:  Use calc_image_size  to help determining the size of the flattened image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "7\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Call calc_image_size\n",
    "\n",
    "# Your Code Here\n",
    "for i in range(4):\n",
    "    image_size = calc_image_size(i+1, 32)\n",
    "    print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnBKf22eMTXw"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self, K):\n",
    "    super(CNN, self).__init__()\n",
    "    \n",
    "    # define the conv layers, flatten and linear layers\n",
    "    \n",
    "    # Your Code Here\n",
    "    self.conv1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=1, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=1, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(32)\n",
    "    )\n",
    "    self.conv2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(64)\n",
    "    )\n",
    "    self.maxPool1 = nn.MaxPool2d((2,2))\n",
    "    self.maxPool2 = nn.MaxPool2d((2,2))\n",
    "    self.linear1 = nn.Linear(64 * 8 * 8, 1024)\n",
    "    self.linear2 = nn.Linear(1024, K)\n",
    "    \n",
    "    self.flatten = nn.Flatten()\n",
    "    \n",
    "  def forward(self, x):\n",
    "    # Your Code Here\n",
    "    # print(f\"{'Input:':<15} {x.shape}\")\n",
    "    z = self.conv1(x)\n",
    "    # print(f\"{'Conv1 done:':<15} {z.shape}\")\n",
    "    z = self.maxPool1(z)\n",
    "    # print(f\"{'MP1 done:':<15} {z.shape}\")\n",
    "    z = self.conv2(z)\n",
    "    # print(f\"{'Conv2 done:':<15} {z.shape}\")\n",
    "    z = self.maxPool2(z)\n",
    "    # print(f\"{'MP2 done:':<15} {z.shape}\")\n",
    "    z = self.flatten(z)\n",
    "    # print(f\"{'Flatten done:':<15} {z.shape}\")\n",
    "    z = nn.ReLU()(self.linear1(z))\n",
    "    # print(f\"{'Linear1 done:':<15} {z.shape}\")\n",
    "    z = nn.Dropout(0.2)(z)\n",
    "    # print(f\"{'Dropout done:':<15} {z.shape}\")\n",
    "    z = self.linear2(z)\n",
    "    # print(f\"{'Linear2 done:':<15} {z.shape}\")\n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 (2) Instantiate the model and display a torchsummary model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "AXzkttj0QIav",
    "outputId": "cf1b38fb-047b-4834-8da2-1106930de272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 32, 32, 32]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 32, 32]          128\n",
      "|    └─ReLU: 2-2                         [-1, 32, 32, 32]          --\n",
      "|    └─BatchNorm2d: 2-3                  [-1, 32, 32, 32]          64\n",
      "|    └─Conv2d: 2-4                       [-1, 32, 32, 32]          1,056\n",
      "|    └─ReLU: 2-5                         [-1, 32, 32, 32]          --\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 32, 32, 32]          64\n",
      "├─MaxPool2d: 1-2                         [-1, 32, 16, 16]          --\n",
      "├─Sequential: 1-3                        [-1, 64, 16, 16]          --\n",
      "|    └─Conv2d: 2-7                       [-1, 64, 16, 16]          2,112\n",
      "|    └─ReLU: 2-8                         [-1, 64, 16, 16]          --\n",
      "|    └─BatchNorm2d: 2-9                  [-1, 64, 16, 16]          128\n",
      "|    └─Conv2d: 2-10                      [-1, 64, 16, 16]          4,160\n",
      "|    └─ReLU: 2-11                        [-1, 64, 16, 16]          --\n",
      "|    └─BatchNorm2d: 2-12                 [-1, 64, 16, 16]          128\n",
      "├─MaxPool2d: 1-4                         [-1, 64, 8, 8]            --\n",
      "├─Flatten: 1-5                           [-1, 4096]                --\n",
      "├─Linear: 1-6                            [-1, 1024]                4,195,328\n",
      "├─Linear: 1-7                            [-1, 10]                  10,250\n",
      "==========================================================================================\n",
      "Total params: 4,213,418\n",
      "Trainable params: 4,213,418\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.93\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.51\n",
      "Params size (MB): 16.07\n",
      "Estimated Total Size (MB): 17.59\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 32, 32, 32]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 32, 32, 32]          128\n",
       "|    └─ReLU: 2-2                         [-1, 32, 32, 32]          --\n",
       "|    └─BatchNorm2d: 2-3                  [-1, 32, 32, 32]          64\n",
       "|    └─Conv2d: 2-4                       [-1, 32, 32, 32]          1,056\n",
       "|    └─ReLU: 2-5                         [-1, 32, 32, 32]          --\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 32, 32, 32]          64\n",
       "├─MaxPool2d: 1-2                         [-1, 32, 16, 16]          --\n",
       "├─Sequential: 1-3                        [-1, 64, 16, 16]          --\n",
       "|    └─Conv2d: 2-7                       [-1, 64, 16, 16]          2,112\n",
       "|    └─ReLU: 2-8                         [-1, 64, 16, 16]          --\n",
       "|    └─BatchNorm2d: 2-9                  [-1, 64, 16, 16]          128\n",
       "|    └─Conv2d: 2-10                      [-1, 64, 16, 16]          4,160\n",
       "|    └─ReLU: 2-11                        [-1, 64, 16, 16]          --\n",
       "|    └─BatchNorm2d: 2-12                 [-1, 64, 16, 16]          128\n",
       "├─MaxPool2d: 1-4                         [-1, 64, 8, 8]            --\n",
       "├─Flatten: 1-5                           [-1, 4096]                --\n",
       "├─Linear: 1-6                            [-1, 1024]                4,195,328\n",
       "├─Linear: 1-7                            [-1, 10]                  10,250\n",
       "==========================================================================================\n",
       "Total params: 4,213,418\n",
       "Trainable params: 4,213,418\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 6.93\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.51\n",
       "Params size (MB): 16.07\n",
       "Estimated Total Size (MB): 17.59\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "K = len(set(train_data.targets))\n",
    "# print(f\"There are {K} classes to target\")\n",
    "model = CNN(K)\n",
    "model.to(device)\n",
    "summary(model, (3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 (1) Use Cross Entropy Loss and Adam optimizer with learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVJ9VRunN5uJ"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 (5) Code training loop for 20 epochs\n",
    "\n",
    "* Calculate both training and test loss\n",
    "* Save training loss and test loss for plotting\n",
    "* Print training loss and test loss at end of every epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_Ux13bnN87z"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "epochs = 30\n",
    "train_losses = np.zeros(epochs)\n",
    "test_losses = np.zeros(epochs)\n",
    "\n",
    "for e in range(epochs):\n",
    "  t0 = datetime.now()\n",
    "  train_loss = []\n",
    "  for inputs, targets in train_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss.append(loss.item())\n",
    "  \n",
    "  train_loss = np.mean(train_loss)\n",
    "\n",
    "  test_loss = []\n",
    "  for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    test_loss.append(loss.item())\n",
    "  test_loss = np.mean(test_loss)\n",
    "\n",
    "  train_losses[e] = train_loss\n",
    "  test_losses[e] = test_loss\n",
    "\n",
    "  dt = datetime.now() - t0\n",
    "  print(f\"Epoch {e+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Duration: {dt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 (1) Plot the train and test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "M0DUdF95Ov7C",
    "outputId": "7d56adb3-6a33-46d9-926c-79a63d2faf53"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 (4 ) Predict the test data and display  results in a confusion matrix. Print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "colab_type": "code",
    "id": "_T5qifQLO2yT",
    "outputId": "a8393d53-5aba-4a38-ed75-ed4b1f00847f"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "x_test = test_data.data\n",
    "y_test = test_data.targets\n",
    "pred_test = np.array([])\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "  inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "  outputs = model(inputs)\n",
    "\n",
    "  _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "  pred_test = np.concatenate((pred_test, predictions.cpu().numpy()))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_test)\n",
    "print(cm)\n",
    "\n",
    "print(f\"Accuracy = {np.trace(cm)/np.sum(cm):.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PyTorch CIFAR Improved.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12bdbd59a1774baab3c8277adc592781": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bbfe879bace4439a0a85af2219ad242": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8e7daaac9d34ee39ecb69e6658e84c9",
       "IPY_MODEL_9ef6aedca5b34e1b84bf9545c917714a"
      ],
      "layout": "IPY_MODEL_e03bd81c35ad4fbdb41a19d5296ac10e"
     }
    },
    "97323a3188bf40d59972a24bdb6fb901": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ef6aedca5b34e1b84bf9545c917714a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12bdbd59a1774baab3c8277adc592781",
      "placeholder": "​",
      "style": "IPY_MODEL_bf0e89e1b9044febbad2ad4400a20780",
      "value": "170500096it [00:03, 42941616.12it/s]"
     }
    },
    "bf0e89e1b9044febbad2ad4400a20780": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c020ed43abf7471981e40c80dfd50ffc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e03bd81c35ad4fbdb41a19d5296ac10e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8e7daaac9d34ee39ecb69e6658e84c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97323a3188bf40d59972a24bdb6fb901",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c020ed43abf7471981e40c80dfd50ffc",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
